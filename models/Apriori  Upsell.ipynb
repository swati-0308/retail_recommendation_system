{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0571ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.10.tar.gz (385 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.7/385.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: psycopg2\n",
      "  Building wheel for psycopg2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psycopg2: filename=psycopg2-2.9.10-cp310-cp310-macosx_10_9_x86_64.whl size=133844 sha256=949d77ac17c9a8afdf38de2ae75895baabe8fe8f9100d0bfbcec99fca280cf23\n",
      "  Stored in directory: /Users/delin/Library/Caches/pip/wheels/15/c2/53/680416c0eed380edec859de7db3a660a47257b174357c11f64\n",
      "Successfully built psycopg2\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5adb10f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2-binary-2.9.10.tar.gz (385 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: psycopg2-binary\n",
      "  Building wheel for psycopg2-binary (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psycopg2-binary: filename=psycopg2_binary-2.9.10-cp310-cp310-macosx_10_9_x86_64.whl size=133921 sha256=e08f685352f30824081263fdea9cf368c8d4c6b13e93b3f751f709787fd0ff3c\n",
      "  Stored in directory: /Users/delin/Library/Caches/pip/wheels/10/26/2e/160fa82a7c017c38715f9103ba8737c3dc69cc48a973e5c5f4\n",
      "Successfully built psycopg2-binary\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a62a3",
   "metadata": {},
   "source": [
    "## Database Connection and Data Retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e5d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Define RDS connection parameters\n",
    "host = \"projects-database.cxgcu68ksihx.us-east-1.rds.amazonaws.com\"\n",
    "port = \"5432\"\n",
    "dbname = \"postgres\"\n",
    "user = \"postgres\"\n",
    "password = \"DATA602_project\"\n",
    "\n",
    "# Establish connection and fetch data\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=host, port=port, database=dbname, user=user, password=password\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM sales_data;\")\n",
    "    data = cur.fetchall()\n",
    "    columns = [desc[0] for desc in cur.description]\n",
    "    ret = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "except Exception as err:\n",
    "    print(f\"Database connection error: {err}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "# Helper to convert frozensets to strings\n",
    "def frozenset_to_string(fset):\n",
    "    return ', '.join(map(str, fset)) if isinstance(fset, frozenset) else str(fset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3d8b6",
   "metadata": {},
   "source": [
    "## Basket Preparation and Apriori Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_basket(data):\n",
    "\n",
    "    return (\n",
    "        data.groupby(['invoiceno', 'description'])['quantity'].sum()\n",
    "        .unstack()\n",
    "        .fillna(0)\n",
    "        .applymap(lambda x: 1 if x > 0 else 0)\n",
    "    )\n",
    "\n",
    "def generate_apriori_rules(basket, min_support=0.03, min_confidence=0.01):\n",
    "  \n",
    "    frequent_itemsets = apriori(basket, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    return rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a6ee6",
   "metadata": {},
   "source": [
    "## Upsell Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4c50464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_upsell_rules(rules, data):\n",
    "  \n",
    "    valid_upsells = []\n",
    "    for _, rule in rules.iterrows():\n",
    "        antecedent_items = list(rule['antecedents'])\n",
    "        consequent_items = list(rule['consequents'])\n",
    "\n",
    "        # Fetch prices for comparison\n",
    "        antecedent_prices = data[data['description'].isin(antecedent_items)]['unitprice'].tolist()\n",
    "        consequent_prices = data[data['description'].isin(consequent_items)]['unitprice'].tolist()\n",
    "\n",
    "        if antecedent_prices and consequent_prices and max(antecedent_prices) < min(consequent_prices):\n",
    "            valid_upsells.append(rule)\n",
    "\n",
    "    return pd.DataFrame(valid_upsells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e3a6f",
   "metadata": {},
   "source": [
    "##  Per-Country Processing and Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ba6fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/delin/anaconda3/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/delin/anaconda3/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/delin/anaconda3/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Users/delin/anaconda3/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsell Recommendations:\n",
      "     country                                        antecedents  \\\n",
      "72    France                         PACK OF 6 SKULL PAPER CUPS   \n",
      "48    France                         PACK OF 6 SKULL PAPER CUPS   \n",
      "47    France                         PACK OF 6 SKULL PAPER CUPS   \n",
      "111     EIRE                          COOK WITH WINE METAL SIGN   \n",
      "240     EIRE  REGENCY TEA PLATE PINK, REGENCY MILK JUG PINK,...   \n",
      "..       ...                                                ...   \n",
      "34    France                            LUNCH BAG RED RETROSPOT   \n",
      "78   Germany                         JUMBO BAG WOODLAND ANIMALS   \n",
      "66    France                  STRAWBERRY LUNCH BOX WITH CUTLERY   \n",
      "30    France                            LUNCH BAG RED RETROSPOT   \n",
      "32    France                            LUNCH BAG RED RETROSPOT   \n",
      "\n",
      "                                           consequents  confidence       lift  \n",
      "72   PACK OF 20 SKULL PAPER NAPKINS, PACK OF 6 SKUL...    0.523810  14.505495  \n",
      "48                        PACK OF 6 SKULL PAPER PLATES    0.714286  14.285714  \n",
      "47                      PACK OF 20 SKULL PAPER NAPKINS    0.619048  13.928571  \n",
      "111                       PLEASE ONE PERSON METAL SIGN    0.538462  12.492308  \n",
      "240                           REGENCY SUGAR BOWL GREEN    1.000000  11.600000  \n",
      "..                                                 ...         ...        ...  \n",
      "34                   STRAWBERRY LUNCH BOX WITH CUTLERY    0.207547   1.556604  \n",
      "78                  ROUND SNACK BOXES SET OF4 WOODLAND    0.363636   1.489850  \n",
      "66                  ROUND SNACK BOXES SET OF4 WOODLAND    0.229167   1.398305  \n",
      "30                            RED RETROSPOT MINI CASES    0.207547   1.383648  \n",
      "32                  ROUND SNACK BOXES SET OF4 WOODLAND    0.226415   1.381516  \n",
      "\n",
      "[318 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "upsell_results = []\n",
    "\n",
    "for country in ret['country'].unique():\n",
    "    country_data = ret[ret['country'] == country]\n",
    "\n",
    "    if not country_data.empty:\n",
    "        # Prepare transactional data\n",
    "        basket = prepare_basket(country_data)\n",
    "\n",
    "        # Generate rules using Apriori\n",
    "        rules = generate_apriori_rules(basket, min_support=0.03, min_confidence=0.01)\n",
    "\n",
    "        if not rules.empty:\n",
    "            # Filter rules for upsell\n",
    "            filtered_upsell = filter_upsell_rules(rules, country_data)\n",
    "\n",
    "            if not filtered_upsell.empty:\n",
    "                filtered_upsell['country'] = country\n",
    "                upsell_results.append(filtered_upsell)\n",
    "\n",
    "if upsell_results:\n",
    "    final_upsell_df = pd.concat(upsell_results, ignore_index=True)\n",
    "\n",
    "    # Convert frozensets to strings for readability\n",
    "    final_upsell_df['antecedents'] = final_upsell_df['antecedents'].apply(frozenset_to_string)\n",
    "    final_upsell_df['consequents'] = final_upsell_df['consequents'].apply(frozenset_to_string)\n",
    "    final_upsell_df_sorted = final_upsell_df.sort_values(by=['lift', 'confidence'], ascending=[False, False])\n",
    "\n",
    "    print(\"Upsell Recommendations:\")\n",
    "    print(final_upsell_df_sorted[['country', 'antecedents', 'consequents', 'confidence', 'lift']])\n",
    "else:\n",
    "    print(\"No upsell recommendations identified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e211f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dab921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
